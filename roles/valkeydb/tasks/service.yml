---
# Create directories and set owner
- name: ">> {{service}} << Directory creation"
  file:
    path: "{{item}}"
    state: directory
    owner: nobody
  with_items:
    - "{{ valkey_haproxy_config_dir }}/{{service}}"
    - "{{ valkey_config_dir }}/{{service}}"
    - "{{ valkey_data_dir }}/{{service}}/valkey"
    - "{{ valkey_data_dir }}/{{service}}/sentinel"
    - "{{ valkey_log_dir }}"

- name: ">> {{service}} << Merge SSL crt and private key into one file for haproxy"
  shell: cat "{{ valkey_haproxy_crt_file }}" "{{ valkey_haproxy_key_file }}" > {{ valkey_haproxy_config_dir }}/{{ service }}/valkey.pem
  args:
    creates: "{{ valkey_haproxy_config_dir }}/{{ service }}/valkey.pem"
  notify: restart haproxy

- name: ">> {{service}} << Set permissions"
  file:
    path: "{{ valkey_haproxy_config_dir }}/{{ service }}/valkey.pem"
    owner: nobody
    mode: 0640
  notify: restart haproxy

- name: ">> {{service}} << Forward sentinel over haproxy with iptables {{ valkey_port }}"
  debug:
    msg: "valkey_port {{ valkey_port }}"

- name: ">> {{service}} << Forward sentinel over haproxy with iptables {{ valkey_port }}"
  ansible.builtin.iptables:
    table: nat
    chain: OUTPUT
    protocol: tcp
    uid_owner: 64446
    destination_port: "{{valkey_port + services[cluster][subcluster][service]['port_offset']}}"
    jump: DNAT
    to_destination: ":{{haproxy_valkey_local_port + services[cluster][subcluster][service]['port_offset']}}"
    comment: "iptables_sentinel_forward_{{valkey_port + services[cluster][subcluster][service]['port_offset']}}"

# Add configs
- name: ">> {{service}} << Add valkey.conf"
  template: src=valkey.conf.j2 dest={{ valkey_config_dir }}/{{service}}/valkey.conf mode=0640 owner=nobody
  register: valkey_conf
  notify: restart valkey

# Add configs
- name: ">> {{service}} << Add users.acl"
  template: src=users.acl.j2 dest={{ valkey_data_dir }}/{{service}}/valkey/users.acl mode=0640 owner=nobody
  register: valkey_conf
  notify: restart valkey
  no_log: true

- name: ">> {{service}} << Add sentinel.conf.j2"
  template: src=sentinel.conf.j2 dest={{ valkey_config_dir }}/{{service}}/ mode=0660 owner=sentinel
  register: sentinel_conf

# Sentinel uses sentinel.conf to write temporary configuration like id,
# so it will be always different from Ansible version, that's why we use tmpl instead
- name: ">> {{service}} << Copy sentinel.conf.j2 to sentinel.conf"
  copy:
    src: "{{ valkey_config_dir }}/{{service}}/sentinel.conf.j2"
    dest: "{{ valkey_config_dir }}/{{service}}/sentinel.conf"
    remote_src: yes
    owner: sentinel
    mode: 0660
  when: sentinel_conf.changed
  notify: restart sentinel

- name: ">> {{service}} << Add haproxy.cfg"
  template: src=haproxy.cfg.j2 dest={{ valkey_haproxy_config_dir }}/{{service}}/haproxy.cfg mode=0640 owner=nobody
  register: haproxy_cfg
  notify: restart haproxy

- name: ">> {{service}} << Run valkey container"
  docker_container:
    name: valkey-{{service}}
    labels: {"name": "valkey-{{service}}"}
    image: valkey/valkey:{{valkey_version}}
    command: valkey-server /etc/valkey.conf
    state: started
    restart_policy: always
    network_mode: host
    read_only: True
    user: 65534
    volumes:
      - "{{ valkey_config_dir }}/{{service}}/valkey.conf:/etc/valkey.conf:ro"
      - "{{ valkey_data_dir }}/{{service}}/valkey:/data:rw"
      - "{{ valkey_log_dir }}:/valkey_log:rw"
  register: valkey_container

- name: ">> {{service}} << Run sentinel container"
  docker_container:
    name: sentinel-{{service}}
    labels: {"name": "sentinel-{{service}}"}
    image: valkey/valkey:{{valkey_version}}
    command: valkey-server /etc/sentinel.conf --sentinel
    state: started
    restart_policy: always
    network_mode: host
    read_only: True
    user: 64446
    volumes:
      - "{{ valkey_config_dir }}/{{service}}/sentinel.conf:/etc/sentinel.conf:rw"
      - "{{ valkey_data_dir }}/{{service}}/sentinel:/data:rw"
  register: sentinel_container

- name: ">> {{service}} << Run haproxy container"
  docker_container:
    name: haproxy-{{service}}
    labels: {"name": "haproxy-{{service}}"}
    image: haproxy:{{haproxy_version}}
    state: started
    restart_policy: always
    network_mode: host
    read_only: True
    user: 65534
    volumes:
      - "{{ valkey_haproxy_config_dir }}/{{service}}/haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro"
      - "{{ valkey_haproxy_config_dir }}/{{ service }}/valkey.pem:/etc/valkey.pem:ro"
  register: haproxy_container

- name: ">> {{service}} << Set fact {{service}}"
  set_fact:
    current_service: "{{service}}"
  tags: [always]

- name: "Notify Handlers Now"
  meta: flush_handlers
  tags: [always]

# Custom subcluster is used when we need to crete new subcluster and connect it as replicas of parent subcluster
# in order to migrade some services from parent (original) subcluster
- set_fact:
    parent_subcluster_var: "{{subcluster}}"
  when: "parent_subcluster_var is not defined"

# Configure roles
- name: ">> {{service}} << Figure out current master using local python script"
  shell: /opt/cent/bin/redis-get-master.py --config {{ valkey_config_dir }}/{{ service }}/valkey.conf --srv1 {{ instances[cluster][subcluster]['srv1'] }} --srv2 {{ instances[cluster][subcluster]['srv2'] }} --srv3 {{ instances[cluster][subcluster]['srv3'] }}
  register: current_master
  changed_when: false

- set_fact:
    current_master: "{{ current_master.stdout }}"
    current_master_ip: "{{ current_master.stdout }}"

- set_fact:
    current_master_ip: "{{ lookup('community.general.dig', current_master) }}"

- name: ">> {{service}} << Show master"
  debug:
    msg: "Current master is {{ current_master }}/{{ current_master_ip }}"

- name: ">> {{service}} << Check if node is configured as master/slave"
  shell: |
      /usr/bin/redis-cli -h localhost -p {{haproxy_valkey_local_port + services[cluster][subcluster][service]['port_offset']}} \
                         -a {{secrets[cluster][subcluster][service]['password']}} info Replication | grep 'master_link_status:up\|role:master' || true
  args:
    executable: /bin/bash
  register: valkey_role
  changed_when: false
  no_log: False

- name: ">> {{ service }} << Configure default master instance"
  command: |
      /usr/bin/redis-cli -h localhost -p {{ haproxy_valkey_local_port + services[cluster][subcluster][service]['port_offset']}} \
                         -a {{ secrets[cluster][subcluster][service]['password']}} slaveof no one
  when:
    - '(ansible_fqdn == current_master or ansible_default_ipv4.address == current_master_ip) and ("master_link_status:up" != valkey_role.stdout)'
    - '(ansible_fqdn == current_master or ansible_default_ipv4.address == current_master_ip) and ("role:master" != valkey_role.stdout)'
  no_log: False

- name: ">> {{ service }} << Configure default slave instance"
  command: |
      /usr/bin/redis-cli -h localhost -p {{ haproxy_valkey_local_port + services[cluster][subcluster][service]['port_offset'] }} \
                         -a {{ secrets[cluster][subcluster][service]['password']}} \
                         slaveof {{ current_master }} \
                         {{ haproxy_valkey_local_port + services[cluster][subcluster][service]['port_offset'] }}
  when:
    - 'ansible_fqdn != current_master and ansible_default_ipv4.address != current_master_ip and ("master_link_status:up" != valkey_role.stdout)'
    - 'ansible_fqdn != current_master and ansible_default_ipv4.address != current_master_ip and ("role:master" != valkey_role.stdout)'
  no_log: False
